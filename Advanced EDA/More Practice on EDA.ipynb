{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3\n",
    "## More EDA: improving expertise in loading, cleaning, and analyzing data\n",
    "\n",
    "The objective of Lab 3 is for you to become more proficient in obtaining and working with different types of data. A particular emphasis will be on dealing with text data.\n",
    "\n",
    "This lab assignment will have 3 components. \n",
    "\n",
    "## Lab 3.A. Complete tutorials from Harvard's CS109 Lab 1\n",
    "\n",
    "Go to https://github.com/cs109/2015lab1 and download the following files in your local Lab3 directory:\n",
    "- https://github.com/cs109/2015lab1/blob/master/all.csv\n",
    "- https://github.com/cs109/2015lab1/blob/master/hamlet.txt\n",
    "\n",
    "We are going to go through the *Lab1-babypython.ipynb* and *Lab1-pythonpandas.ipynb*. The orginal Python notebooks were written in Python 2. We converted the notebooks into Python 3, which can be downloaded from here\"\n",
    "\n",
    "- https://github.com/cis3715-temple-2020/cis3715-temple-2020.github.io/blob/master/Lab3/CIS3715-Lab3.A-babypython_py3.ipynb\n",
    "- https://github.com/cis3715-temple-2020/cis3715-temple-2020.github.io/blob/master/Lab3/CIS3715-Lab3.A-pythonpandas_py3.ipynb\n",
    "\n",
    "Study all the code and run every block of code from the *babypython* tutorial. It covers many of the things you already learned in your Labs 1 and 2, so it is a good refresher. However, there are some new things. In particular, you will learn how to load a pure textual file and process it to find counts of all the unique words (also called the tokens) in the text.\n",
    "\n",
    "Study all the code and run every block of code from the *pythonpandas* tutorial. Again, you will find there many things you already know. However, the novelty here is in processing and analysis of a slightly messy tabular data than was the case with the *Auto MPG data*.\n",
    "\n",
    "\n",
    "\n",
    "**Deliverable**: submit the two .ipynb files after you have run all the lines of code. We will appreciate if we see that you put some extra effort, such as trying to modify existing code, enter new lines of code, or provide comments in the text. Make sure any modifications are easily visible by us for the grading purposes.\n",
    "\n",
    "## Lab 3.B. Movie Lens Data\n",
    "\n",
    "In this part of the lab, you will be working on an exercise that is a slightly modified and shortened version of https://github.com/cs109/2015/blob/master/Lectures/02-DataScrapingQuizzes.ipynb. In particular, you will learn how to load and analyze MoviLens data, which contains ratings of multiple movies by multiple users.\n",
    "\n",
    "**The MovieLens data**\n",
    "\n",
    "http://grouplens.org/datasets/movielens/\n",
    "\n",
    "Take some time to learn about the data, because it will be helpful to do the assignment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## all imports\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import requests\n",
    "import bs4 # beautiful soup\n",
    "import time\n",
    "import operator\n",
    "import socket\n",
    "import re # regular expressions\n",
    "\n",
    "from pandas import Series\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>85711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>94043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>32067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>43537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>15213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  age sex  occupation zip_code\n",
       "0        1   24   M  technician    85711\n",
       "1        2   53   F       other    94043\n",
       "2        3   23   M      writer    32067\n",
       "3        4   24   M  technician    43537\n",
       "4        5   33   F       other    15213"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the user data:\n",
    "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']    # pass in column names for each CSV\n",
    "\n",
    "users = pd.read_csv(\n",
    "    'http://files.grouplens.org/datasets/movielens/ml-100k/u.user', \n",
    "    sep='|', names=u_cols, engine='python')\n",
    "\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>unix_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  unix_timestamp\n",
       "0      196       242       3       881250949\n",
       "1      186       302       3       891717742\n",
       "2       22       377       1       878887116\n",
       "3      244        51       2       880606923\n",
       "4      166       346       1       886397596"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the ratings:\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv(\n",
    "    'http://files.grouplens.org/datasets/movielens/ml-100k/u.data', \n",
    "    sep='\\t', names=r_cols, engine='python')\n",
    "\n",
    "ratings.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>video_release_date</th>\n",
       "      <th>imdb_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>Shanghai Triad (Yao a yao yao dao waipo qiao) ...</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/Title?Yao+a+yao+yao+dao+wai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>Twelve Monkeys (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Twelve%20Monk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                                              title release_date  \\\n",
       "0         1                                   Toy Story (1995)  01-Jan-1995   \n",
       "1         2                                   GoldenEye (1995)  01-Jan-1995   \n",
       "2         3                                  Four Rooms (1995)  01-Jan-1995   \n",
       "3         4                                  Get Shorty (1995)  01-Jan-1995   \n",
       "4         5                                     Copycat (1995)  01-Jan-1995   \n",
       "5         6  Shanghai Triad (Yao a yao yao dao waipo qiao) ...  01-Jan-1995   \n",
       "6         7                              Twelve Monkeys (1995)  01-Jan-1995   \n",
       "\n",
       "   video_release_date                                           imdb_url  \n",
       "0                 NaN  http://us.imdb.com/M/title-exact?Toy%20Story%2...  \n",
       "1                 NaN  http://us.imdb.com/M/title-exact?GoldenEye%20(...  \n",
       "2                 NaN  http://us.imdb.com/M/title-exact?Four%20Rooms%...  \n",
       "3                 NaN  http://us.imdb.com/M/title-exact?Get%20Shorty%...  \n",
       "4                 NaN  http://us.imdb.com/M/title-exact?Copycat%20(1995)  \n",
       "5                 NaN  http://us.imdb.com/Title?Yao+a+yao+yao+dao+wai...  \n",
       "6                 NaN  http://us.imdb.com/M/title-exact?Twelve%20Monk...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the movies data\n",
    "# The movies file contains columns indicating the movie's genres\n",
    "# Let's only load the first five columns of the file with usecols\n",
    "m_cols = ['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url']\n",
    "\n",
    "movies = pd.read_csv(\n",
    "    'http://files.grouplens.org/datasets/movielens/ml-100k/u.item', \n",
    "    sep='|', names=m_cols, usecols=range(5), engine='python', encoding = \"ISO-8859-1\")\n",
    "\n",
    "movies.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get information about the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_id                int64\n",
      "title                  object\n",
      "release_date           object\n",
      "video_release_date    float64\n",
      "imdb_url               object\n",
      "dtype: object\n",
      "\n",
      "          movie_id  video_release_date\n",
      "count  1682.000000                 0.0\n",
      "mean    841.500000                 NaN\n",
      "std     485.695893                 NaN\n",
      "min       1.000000                 NaN\n",
      "25%     421.250000                 NaN\n",
      "50%     841.500000                 NaN\n",
      "75%    1261.750000                 NaN\n",
      "max    1682.000000                 NaN\n"
     ]
    }
   ],
   "source": [
    "print(movies.dtypes)\n",
    "print()\n",
    "print(movies.describe())\n",
    "# *** Why only those two columns? ***\n",
    "# One represents the dataframe's column name and the other is the object type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why only 2 columns show for .describe() method?\n",
    "Because .describe() returns a statistical summary of each column. If a column is a not of either an integer or float type, then it cannot return a statistical summary for that. \n",
    "\n",
    "However, using include=\"all\" option would include some statistical summary for object columns as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>video_release_date</th>\n",
       "      <th>imdb_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1682.000000</td>\n",
       "      <td>1682</td>\n",
       "      <td>1681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unique</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1664</td>\n",
       "      <td>240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>top</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Designated Mourner, The (1997)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Fly%20Away%20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>freq</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>215</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>841.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>485.695893</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>421.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>841.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1261.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1682.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           movie_id                           title release_date  \\\n",
       "count   1682.000000                            1682         1681   \n",
       "unique          NaN                            1664          240   \n",
       "top             NaN  Designated Mourner, The (1997)  01-Jan-1995   \n",
       "freq            NaN                               2          215   \n",
       "mean     841.500000                             NaN          NaN   \n",
       "std      485.695893                             NaN          NaN   \n",
       "min        1.000000                             NaN          NaN   \n",
       "25%      421.250000                             NaN          NaN   \n",
       "50%      841.500000                             NaN          NaN   \n",
       "75%     1261.750000                             NaN          NaN   \n",
       "max     1682.000000                             NaN          NaN   \n",
       "\n",
       "        video_release_date                                           imdb_url  \n",
       "count                  0.0                                               1679  \n",
       "unique                 NaN                                               1660  \n",
       "top                    NaN  http://us.imdb.com/M/title-exact?Fly%20Away%20...  \n",
       "freq                   NaN                                                  2  \n",
       "mean                   NaN                                                NaN  \n",
       "std                    NaN                                                NaN  \n",
       "min                    NaN                                                NaN  \n",
       "25%                    NaN                                                NaN  \n",
       "50%                    NaN                                                NaN  \n",
       "75%                    NaN                                                NaN  \n",
       "max                    NaN                                                NaN  "
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting data:\n",
    "\n",
    "* DataFrame => group of Series with shared index\n",
    "* single DataFrame column => Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  age sex  occupation zip_code\n",
      "0        1   24   M  technician    85711\n",
      "1        2   53   F       other    94043\n",
      "2        3   23   M      writer    32067\n",
      "3        4   24   M  technician    43537\n",
      "4        5   33   F       other    15213\n",
      "\n",
      "\n",
      "0    technician\n",
      "1         other\n",
      "2        writer\n",
      "3    technician\n",
      "4         other\n",
      "Name: occupation, dtype: object\n",
      "\n",
      "\n",
      "   occupation sex\n",
      "0  technician   M\n",
      "1       other   F\n",
      "2      writer   M\n",
      "3  technician   M\n",
      "4       other   F\n",
      "\n",
      "\n",
      "user_id                4\n",
      "age                   24\n",
      "sex                    M\n",
      "occupation    technician\n",
      "zip_code           43537\n",
      "Name: 3, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(users.head())\n",
    "print('\\n')\n",
    "print(users['occupation'].head())\n",
    "print('\\n')\n",
    "## *** Where did the nice design go? ***\n",
    "columns_you_want = ['occupation', 'sex'] \n",
    "print(users[columns_you_want].head())\n",
    "print('\\n')\n",
    "print(users.iloc[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering data:\n",
    "\n",
    "Select users older than 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>94043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>15213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>M</td>\n",
       "      <td>executive</td>\n",
       "      <td>98101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>57</td>\n",
       "      <td>M</td>\n",
       "      <td>administrator</td>\n",
       "      <td>91344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>M</td>\n",
       "      <td>administrator</td>\n",
       "      <td>05201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  age sex     occupation zip_code\n",
       "1        2   53   F          other    94043\n",
       "4        5   33   F          other    15213\n",
       "5        6   42   M      executive    98101\n",
       "6        7   57   M  administrator    91344\n",
       "7        8   36   M  administrator    05201"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract data within a range\n",
    "oldUsers = users[users.age > 25]\n",
    "oldUsers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1**: \n",
    "* show users aged 40 and male\n",
    "* show the mean age of female programmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     user_id  age sex  occupation zip_code\n",
      "18        19   40   M   librarian    02138\n",
      "82        83   40   M       other    44133\n",
      "115      116   40   M  healthcare    97232\n",
      "199      200   40   M  programmer    93402\n",
      "283      284   40   M   executive    92629\n",
      "     user_id  age sex  occupation zip_code\n",
      "291      292   35   F  programmer    94703\n",
      "299      300   26   F  programmer    55106\n",
      "351      352   37   F  programmer    55105\n",
      "403      404   29   F  programmer    55108\n",
      "420      421   38   F  programmer    55105\n",
      "For male users at 40\n",
      "          user_id   age\n",
      "count   14.000000  14.0\n",
      "mean   415.785714  40.0\n",
      "std    291.416746   0.0\n",
      "min     19.000000  40.0\n",
      "25%    221.000000  40.0\n",
      "50%    333.500000  40.0\n",
      "75%    626.500000  40.0\n",
      "max    918.000000  40.0\n",
      "Female programmers\n",
      "          user_id        age\n",
      "count    6.000000   6.000000\n",
      "mean   411.166667  32.166667\n",
      "std    149.987222   5.115336\n",
      "min    292.000000  26.000000\n",
      "25%    313.000000  28.250000\n",
      "50%    378.000000  32.000000\n",
      "75%    416.750000  36.500000\n",
      "max    698.000000  38.000000\n",
      "The mean age of female programmers is: \n",
      "32.166666666666664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "## users aged 40 AND male\n",
    "# your code here\n",
    "male_and_40 = users[users[\"sex\"] == \"M\"][users[\"age\"] == 40]\n",
    "print(male_and_40.head())\n",
    "\n",
    "## users who are female and programmers\n",
    "# your code here\n",
    "female_programmer = users[users[\"sex\"] == \"F\"][users[\"occupation\"] == \"programmer\"]\n",
    "print(female_programmer.head())\n",
    "\n",
    "## show statistic summary or compute mean\n",
    "# your code here\n",
    "print(\"For male users at 40\")\n",
    "print(male_and_40.describe())\n",
    "print(\"Female programmers\")\n",
    "print(female_programmer.describe())\n",
    "\n",
    "# computing the mean age of female programmers\n",
    "print(\"The mean age of female programmers is: \")\n",
    "print(np.mean(female_programmer.age))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find Diligent Users\n",
    "\n",
    "- split data per user ID\n",
    "- count ratings\n",
    "- combine result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  movie_id  rating  unix_timestamp\n",
      "0      196       242       3       881250949\n",
      "1      186       302       3       891717742\n",
      "2       22       377       1       878887116\n",
      "3      244        51       2       880606923\n",
      "4      166       346       1       886397596\n",
      "         movie_id  rating  unix_timestamp\n",
      "user_id                                  \n",
      "1             272     272             272\n",
      "2              62      62              62\n",
      "3              54      54              54\n",
      "4              24      24              24\n",
      "5             175     175             175\n"
     ]
    }
   ],
   "source": [
    "print(ratings.head())\n",
    "## split data per user ID\n",
    "grouped_data = ratings.groupby('user_id')\n",
    "\n",
    "## count and combine\n",
    "ratings_per_user = grouped_data.count()\n",
    "\n",
    "print(ratings_per_user.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2**:\n",
    "* get the average rating per movie\n",
    "* advanced: get the movie titles with the highest average rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average rating per movie is movie_id\n",
      "1       3.878319\n",
      "2       3.206107\n",
      "3       3.033333\n",
      "4       3.550239\n",
      "5       3.302326\n",
      "          ...   \n",
      "1678    1.000000\n",
      "1679    3.000000\n",
      "1680    2.000000\n",
      "1681    3.000000\n",
      "1682    3.000000\n",
      "Name: rating, Length: 1682, dtype: float64\n",
      "The overall average movie rating is,  3.52986\n",
      "The maximum averaged rating is \n",
      " 5.0\n",
      "Good movie ids: \n",
      "7         465\n",
      "11       1014\n",
      "12        222\n",
      "16        387\n",
      "26         95\n",
      "         ... \n",
      "99961      91\n",
      "99962     479\n",
      "99963     199\n",
      "99978     975\n",
      "99996     204\n",
      "Name: movie_id, Length: 21201, dtype: int64\n",
      "Best movie titles \n",
      "0                                        Toy Story (1995)\n",
      "1                                        GoldenEye (1995)\n",
      "2                                       Four Rooms (1995)\n",
      "3                                       Get Shorty (1995)\n",
      "4                                          Copycat (1995)\n",
      "                              ...                        \n",
      "1638                  Bitter Sugar (Azucar Amargo) (1996)\n",
      "1641                             Some Mother's Son (1996)\n",
      "1642                                    Angel Baby (1995)\n",
      "1652    Entertaining Angels: The Dorothy Day Story (1996)\n",
      "1655                                   Little City (1998)\n",
      "Name: title, Length: 1172, dtype: object\n",
      "Best 10 movies are:\n",
      "\n",
      "0                                     Toy Story (1995)\n",
      "1                                     GoldenEye (1995)\n",
      "2                                    Four Rooms (1995)\n",
      "3                                    Get Shorty (1995)\n",
      "4                                       Copycat (1995)\n",
      "5    Shanghai Triad (Yao a yao yao dao waipo qiao) ...\n",
      "6                                Twelve Monkeys (1995)\n",
      "7                                          Babe (1995)\n",
      "8                              Dead Man Walking (1995)\n",
      "9                                   Richard III (1995)\n",
      "Name: title, dtype: object\n",
      "Number of ratings per movie: \n",
      "movie_id\n",
      "1       452\n",
      "2       131\n",
      "3        90\n",
      "4       209\n",
      "5        86\n",
      "       ... \n",
      "1678      1\n",
      "1679      1\n",
      "1680      1\n",
      "1681      1\n",
      "1682      1\n",
      "Name: rating, Length: 1682, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## split data per movie\n",
    "# your code here\n",
    "grouped_rating = ratings.groupby('movie_id')\n",
    "\n",
    "## average and combine\n",
    "# your code here\n",
    "average_rating = grouped_rating['rating'].agg('mean')\n",
    "print(\"The average rating per movie is\", average_rating)\n",
    "\n",
    "print(\"The overall average movie rating is, \", np.mean(ratings['rating']))\n",
    "## get the maximum rating\n",
    "# your code here\n",
    "maximum_rating = np.max(average_rating)\n",
    "print(\"The maximum averaged rating is \\n\", maximum_rating)\n",
    "\n",
    "## get movie ids with that rating\n",
    "# your code here\n",
    "max_rate_movies = ratings[ratings['rating'] == maximum_rating]\n",
    "\n",
    "print(\"Good movie ids: \",)\n",
    "## get the movie title\n",
    "# your code here\n",
    "print(max_rate_movies['movie_id'])\n",
    "\n",
    "print(\"Best movie titles \",)\n",
    "## get number of ratings per movie\n",
    "# your code here\n",
    "\n",
    "# source consulted:\n",
    "# https://stackoverflow.com/questions/33352280/pandas-boolean-indexing-with-item-in-list-syntax\n",
    "print(movies.loc[movies['movie_id'].isin(max_rate_movies['movie_id']), 'title'])\n",
    "\n",
    "print(\"Best 10 movies are:\\n\")\n",
    "print(movies.loc[movies['movie_id'].isin(max_rate_movies['movie_id']), 'title'][:10])\n",
    "\n",
    "# get number of ratings per movie\n",
    "print(\"Number of ratings per movie: \",)\n",
    "\n",
    "# this works too but gives a little bit of more than\n",
    "# necessary information\n",
    "# print(grouped_rating.count())\n",
    "\n",
    "print(grouped_rating['rating'].agg('count'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**:\n",
    "* get the average rating per user\n",
    "* list all occupations and if they are male or female dominant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id\n",
      "1      3.610294\n",
      "2      3.709677\n",
      "3      2.796296\n",
      "4      4.333333\n",
      "5      2.874286\n",
      "         ...   \n",
      "939    4.265306\n",
      "940    3.457944\n",
      "941    4.045455\n",
      "942    4.265823\n",
      "943    3.410714\n",
      "Name: rating, Length: 943, dtype: float64\n",
      "sex             F    M dominant_sex\n",
      "occupation                         \n",
      "administrator  36   43            M\n",
      "artist         13   15            M\n",
      "doctor          0    7            M\n",
      "educator       26   69            M\n",
      "engineer        2   65            M\n",
      "entertainment   2   16            M\n",
      "executive       3   29            M\n",
      "healthcare     11    5            F\n",
      "homemaker       6    1            F\n",
      "lawyer          2   10            M\n",
      "librarian      29   22            F\n",
      "marketing      10   16            M\n",
      "none            4    5            M\n",
      "other          36   69            M\n",
      "programmer      6   60            M\n",
      "retired         1   13            M\n",
      "salesman        3    9            M\n",
      "scientist       3   28            M\n",
      "student        60  136            M\n",
      "technician      1   26            M\n",
      "writer         19   26            M\n",
      "number of male users: \n",
      "670\n",
      "number of female users: \n",
      "273\n"
     ]
    }
   ],
   "source": [
    "## get the average rating per user\n",
    "# your code here\n",
    "grouped_user = ratings.groupby('user_id')\n",
    "average_rating_user = grouped_user['rating'].agg('mean')\n",
    "print(average_rating_user)\n",
    "\n",
    "\n",
    "# list all occupations and if they are male or female dominant\n",
    "# your code here\n",
    "total_users = users.shape[0]\n",
    "m_f_crosstab = pd.crosstab(users['occupation'],users['sex'])\n",
    "m_f_dominant = m_f_crosstab.copy()\n",
    "\n",
    "# source consulted\n",
    "# https://stackoverflow.com/questions/50375985/pandas-add-column-with-value-based-on-condition-based-on-other-columns\n",
    "m_f_dominant.loc[m_f_dominant['F'] == m_f_dominant['M'], 'dominant_sex'] = 'None'\n",
    "m_f_dominant.loc[m_f_dominant['F'] > m_f_dominant['M'], 'dominant_sex'] = 'F'\n",
    "m_f_dominant.loc[m_f_dominant['F'] < m_f_dominant['M'], 'dominant_sex'] = 'M'\n",
    "\n",
    "# print(m_f_dominant['dominant_sex'])\n",
    "print(m_f_dominant)\n",
    "\n",
    "print('number of male users: ')\n",
    "print(sum(users['sex'] == 'M'))\n",
    "\n",
    "print('number of female users: ')\n",
    "print(sum(users['sex'] == 'F'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "occupation\n",
       "administrator    38.746835\n",
       "artist           31.392857\n",
       "doctor           43.571429\n",
       "educator         42.010526\n",
       "engineer         36.388060\n",
       "entertainment    29.222222\n",
       "executive        38.718750\n",
       "healthcare       41.562500\n",
       "homemaker        32.571429\n",
       "lawyer           36.750000\n",
       "librarian        40.000000\n",
       "marketing        37.615385\n",
       "none             26.555556\n",
       "other            34.523810\n",
       "programmer       33.121212\n",
       "retired          63.071429\n",
       "salesman         35.666667\n",
       "scientist        35.548387\n",
       "student          22.081633\n",
       "technician       33.148148\n",
       "writer           36.311111\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_crosstab = users.groupby('occupation').agg('mean')['age']\n",
    "age_crosstab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.05196182396607"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(users['age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4**:\n",
    "- produce a 1-page document that uses a combination of text, tables, and figures that provide some interesting insights about the Movie Lens data. You should feel free to use outside sources to produce the report, as long as you acknowledge your sources. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 3.C. HTML Data\n",
    "\n",
    "In this part of the lab, you will be also be working on an exercise that is a slightly modified and shortened version of https://github.com/cs109/2015/blob/master/Lectures/02-DataScrapingQuizzes.ipynb. In particular, you will learn how to load and analyze html data.\n",
    "\n",
    "HTML:\n",
    "* HyperText Markup Language\n",
    "* standard for creating webpages\n",
    "* HTML tags \n",
    "    - have angle brackets\n",
    "    - typically come in pairs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example for a minimal webpage defined in HTML tags. The root tag is 'html' and then you have the 'head' tag. This part of the page typically includes the title of the page and might also have other meta information like the author or keywords that are important for search engines. The 'body' tag marks the actual content of the page. You can play around with the 'h2' tag trying different header levels. They range from 1 to 6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>\n",
       "<html>\n",
       "  <head>\n",
       "    <title>This is a title</title>\n",
       "  </head>\n",
       "  <body>\n",
       "    <h2> Test </h2>\n",
       "    <p>Hello world!</p>\n",
       "  </body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htmlString = \"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "  <head>\n",
    "    <title>This is a title</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <h2> Test </h2>\n",
    "    <p>Hello world!</p>\n",
    "  </body>\n",
    "</html>\"\"\"\n",
    "\n",
    "htmlOutput = HTML(htmlString)\n",
    "htmlOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful Tags:\n",
    "\n",
    "* heading\n",
    "`<h1></h1> ... <h6></h6>`\n",
    "\n",
    "* paragraph\n",
    "`<p></p>` \n",
    "\n",
    "* line break\n",
    "`<br>` \n",
    "\n",
    "* link with attribute\n",
    "\n",
    "`<a href=\"http://www.example.com/\">An example link</a>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping with Python:\n",
    "\n",
    "Example of a simple webpage: http://www.crummy.com/software/BeautifulSoup\n",
    "\n",
    "Good news: \n",
    "    - some browsers help\n",
    "    - look for: inspect element\n",
    "    - need only basic html\n",
    "    - try 'Ctrl-Shift I' in Chrome\n",
    "    - try 'Command-Option I' in Safari\n",
    "   \n",
    "Different useful libraries:\n",
    "    - urllib\n",
    "    - beautifulsoup\n",
    "    - pattern\n",
    "    - soupy\n",
    "    - LXML\n",
    "    - ...\n",
    " \n",
    "The following cell just defines a url as a string and then reads the data from that url using the `urllib` library. If you uncomment the print command you see that we got the whole HTML content of the page into the string variable source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\"\n",
      "\"http://www.w3.org/TR/REC-html40/transitional.dtd\">\n",
      "<html>\n",
      "<head>\n",
      "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
      "<title>Beautiful Soup: We called him Tortoise because he taught us.</title>\n",
      "<link rev=\"made\" href=\"mailto:leonardr@segfault.org\">\n",
      "<link rel=\"stylesheet\" type=\"text/css\" href=\"/nb/themes/Default/nb.css\">\n",
      "<meta name=\"Description\" content=\"Beautiful Soup: a library designed for screen-scraping HTML and XML.\">\n",
      "<meta name=\"generator\" content=\"Markov Approximation 1.4 (module: leonardr)\">\n",
      "<meta name=\"author\" content=\"Leonard Richardson\">\n",
      "</head>\n",
      "<body bgcolor=\"white\" text=\"black\" link=\"blue\" vlink=\"660066\" alink=\"red\">\n",
      "<style>\n",
      "#tidelift { }\n",
      "\n",
      "#tidelift a {\n",
      " border: 1px solid #666666;\n",
      " margin-left: auto;\n",
      " padding: 10px;\n",
      " text-decoration: none;\n",
      "}\n",
      "\n",
      "#tidelift .cta {\n",
      " background: url(\"tidelift.svg\") no-repeat;\n",
      " padding-left: 30px;\n",
      "}\n",
      "</style>\t\t   \n",
      "\n",
      "<img align=\"right\" src=\"10.1.jpg\" width=\"250\"><br />\n",
      "\n",
      "<p>[ <a href=\"#Download\">Download</a> | <a\n",
      "href=\"bs4/doc/\">Documentation</a> | <a href=\"#HallOfFame\">Hall of Fame</a> | <a href=\"enterprise.html\">For enterprise</a> | <a href=\"https://code.launchpad.net/beautifulsoup\">Source</a> | <a href=\"https://bazaar.launchpad.net/%7Eleonardr/beautifulsoup/bs4/view/head:/CHANGELOG\">Changelog</a> | <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">Discussion group</a>  | <a href=\"zine/\">Zine</a> ]</p>\n",
      "\n",
      "<div align=\"center\">\n",
      "\n",
      "<a href=\"bs4/download/\"><h1>Beautiful Soup</h1></a>\n",
      "\n",
      "</div>\n",
      "\n",
      "<p>You didn't write that awful page. You're just trying to get some\n",
      "data out of it. Beautiful Soup is here to help. Since 2004, it's been\n",
      "saving programmers hours or days of work on quick-turnaround\n",
      "screen scraping projects.</p>\n",
      "\n",
      "<p>Beautiful Soup is a Python library designed for quick turnaround\n",
      "projects like screen-scraping. Three features make it powerful:\n",
      "\n",
      "<ol>\n",
      "\n",
      "<li>Beautiful Soup provides a few simple methods and Pythonic idioms\n",
      "for navigating, searching, and modifying a parse tree: a toolkit for\n",
      "dissecting a document and extracting what you need. It doesn't take\n",
      "much code to write an application\n",
      "\n",
      "<li>Beautiful Soup automatically converts incoming documents to\n",
      "Unicode and outgoing documents to UTF-8. You don't have to think\n",
      "about encodings, unless the document doesn't specify an encoding and\n",
      "Beautiful Soup can't detect one. Then you just have to specify the\n",
      "original encoding.\n",
      "\n",
      "<li>Beautiful Soup sits on top of popular Python parsers like <a\n",
      "href=\"http://lxml.de/\">lxml</a> and <a\n",
      "href=\"http://code.google.com/p/html5lib/\">html5lib</a>, allowing you\n",
      "to try out different parsing strategies or trade speed for\n",
      "flexibility.\n",
      "\n",
      "</ol>\n",
      "\n",
      "<p>Beautiful Soup parses anything you give it, and does the tree\n",
      "traversal stuff for you. You can tell it \"Find all the links\", or\n",
      "\"Find all the links of class <tt>externalLink</tt>\", or \"Find all the\n",
      "links whose urls match \"foo.com\", or \"Find the table heading that's\n",
      "got bold text, then give me that text.\"\n",
      "\n",
      "<p>Valuable data that was once locked up in poorly-designed websites\n",
      "is now within your reach. Projects that would have taken hours take\n",
      "only minutes with Beautiful Soup.\n",
      "\n",
      "<p>Interested? <a href=\"bs4/doc/\">Read more.</a>\n",
      "\n",
      "<h3>Getting and giving support</h3>\n",
      "\n",
      "<div id=\"tidelift\" align=\"center\">\n",
      "<a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&utm_medium=referral&utm_campaign=enterprise\" target=\"_blank\">\n",
      " <span class=\"cta\">\n",
      "  Beautiful Soup for enterprise available via Tidelift\n",
      " </span>\n",
      "</a>\n",
      "</div>\n",
      "\n",
      "<p>If you have questions, send them to <a\n",
      "href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">the discussion\n",
      "group</a>. If you find a bug, <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file it on Launchpad</a>. If it's a security vulnerability, report it confidentially through <a href=\"https://tidelift.com/security\">Tidelift</a>.</p>\n",
      "\n",
      "<p>If you use Beautiful Soup as part of your work, please consider a <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&utm_medium=referral&utm_campaign=website\">Tidelift subscription</a>. This will support many of the free software projects your organization depends on, not just Beautiful Soup.\n",
      "\n",
      "\n",
      "<p>If Beautiful Soup is useful to you on a personal level, you might like to read <a href=\"zine/\"><i>Tool Safety</i></a>, a short zine I wrote about what I learned about software development from working on Beautiful Soup. Thanks!</p>\n",
      "</div>\n",
      "\n",
      "\n",
      "<a name=\"Download\"><h2>Download Beautiful Soup</h2></a>\n",
      "\n",
      "<p>The current release is <a href=\"bs4/download/\">Beautiful Soup\n",
      "4.8.2</a> (December 24, 2019). You can install Beautiful Soup 4 with\n",
      "<code>pip install beautifulsoup4</code>.\n",
      "\n",
      "<p>In Debian and Ubuntu, Beautiful Soup is available as the\n",
      "<code>python-bs4</code> package (for Python 2) or the\n",
      "<code>python3-bs4</code> package (for Python 3). In Fedora it's\n",
      "available as the <code>python-beautifulsoup4</code> package.\n",
      "\n",
      "<p>Beautiful Soup is licensed under the MIT license, so you can also\n",
      "download the tarball, drop the <code>bs4/</code> directory into almost\n",
      "any Python application (or into your library path) and start using it\n",
      "immediately. (If you want to do this under Python 3, you will need to\n",
      "manually convert the code using <code>2to3</code>.)\n",
      "\n",
      "<p>Beautiful Soup 4 works on both Python 2 (2.7+) and Python\n",
      "3. Support for Python 2 will be discontinued on or after December 31,\n",
      "2020&mdash;one year after the Python 2 sunsetting date.\n",
      "\n",
      "<h3>Beautiful Soup 3</h3>\n",
      "\n",
      "<p>Beautiful Soup 3 was the official release line of Beautiful Soup\n",
      "from May 2006 to March 2012. It does not support Python 3 and it will\n",
      "be discontinued on or after December 31, 2020&mdash;one year after the\n",
      "Python 2 sunsetting date. If you have any active projects using\n",
      "Beautiful Soup 3, you should migrate to Beautiful Soup 4 as part of\n",
      "your Python 3 conversion.\n",
      "\n",
      "<p><a\n",
      "href=\"http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html\">Here's\n",
      "the Beautiful Soup 3 documentation.</a>\n",
      "\n",
      "<p>The current and hopefully final release of Beautiful Soup 3 is <a\n",
      "href=\"download/3.x/BeautifulSoup-3.2.2.tar.gz\">3.2.2</a> (October 5,\n",
      "2019). It's the <code>BeautifulSoup</code> package on pip. It's also\n",
      "available as <code>python-beautifulsoup</code> in Debian and Ubuntu,\n",
      "and as <code>python-BeautifulSoup</code> in Fedora.\n",
      "\n",
      "<p>Once Beautiful Soup 3 is discontinued, these package names will be available for use by a more recent version of Beautiful Soup.\n",
      "\n",
      "<p>Beautiful Soup 3, like Beautiful Soup 4, is <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup?utm_source=pypi-beautifulsoup&utm_medium=referral&utm_campaign=website\">supported through Tidelift</a>.</p>\n",
      "\n",
      "<a name=\"HallOfFame\"><h2>Hall of Fame</h2></a>\n",
      "\n",
      "<p>Over the years, Beautiful Soup has been used in hundreds of\n",
      "different projects. There's no way I can list them all, but I want to\n",
      "highlight a few high-profile projects. Beautiful Soup isn't what makes\n",
      "these projects interesting, but it did make their completion easier:\n",
      "\n",
      "<ul>\n",
      "\n",
      "<li><a\n",
      " href=\"http://www.nytimes.com/2007/10/25/arts/design/25vide.html\">\"Movable\n",
      " Type\"</a>, a work of digital art on display in the lobby of the New\n",
      " York Times building, uses Beautiful Soup to scrape news feeds.\n",
      "\n",
      "<li>Reddit uses Beautiful Soup to <a\n",
      "href=\"https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py\">parse\n",
      "a page that's been linked to and find a representative image</a>.\n",
      "\n",
      "<li>Alexander Harrowell uses Beautiful Soup to <a\n",
      " href=\"http://www.harrowell.org.uk/viktormap.html\">track the business\n",
      " activities</a> of an arms merchant.\n",
      "\n",
      "<li>The developers of Python itself used Beautiful Soup to <a\n",
      "href=\"http://svn.python.org/view/tracker/importer/\">migrate the Python\n",
      "bug tracker from Sourceforge to Roundup</a>.\n",
      "\n",
      "<li>The <a href=\"http://www2.ljworld.com/\">Lawrence Journal-World</a>\n",
      "uses Beautiful Soup to <A\n",
      "href=\"http://www.b-list.org/weblog/2010/nov/02/news-done-broke/\">gather\n",
      "statewide election results</a>.\n",
      "\n",
      "<li>The <a href=\"http://esrl.noaa.gov/gsd/fab/\">NOAA's Forecast\n",
      "Applications Branch</a> uses Beautiful Soup in <a\n",
      "href=\"http://laps.noaa.gov/topograbber/\">TopoGrabber</a>, a script for\n",
      "downloading \"high resolution USGS datasets.\"\n",
      "\n",
      "</ul>\n",
      "\n",
      "<p>If you've used Beautiful Soup in a project you'd like me to know\n",
      "about, please do send email to me or <a\n",
      "href=\"http://groups.google.com/group/beautifulsoup/\">the discussion\n",
      "group</a>.\n",
      "\n",
      "<h2>Development</h2>\n",
      "\n",
      "<p>Development happens at <a\n",
      "href=\"https://launchpad.net/beautifulsoup\">Launchpad</a>. You can <a\n",
      "href=\"https://code.launchpad.net/beautifulsoup/\">get the source\n",
      "code</a> or <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file\n",
      "bugs</a>.<hr><table><tr><td valign=\"top\">\n",
      "<p>This document (<a href=\"/source/software/BeautifulSoup/index.bhtml\">source</a>) is part of Crummy, the webspace of <a href=\"/self/\">Leonard Richardson</a> (<a href=\"/self/contact.html\">contact information</a>). It was last modified on Friday, January 31 2020, 13:44:05 Nowhere Standard Time and last built on Monday, February 17 2020, 04:00:02 Nowhere Standard Time.</p><p><table class=\"licenseText\"><tr><td><a href=\"http://creativecommons.org/licenses/by-sa/2.0/\"><img border=\"0\" src=\"/nb//resources/img/somerights20.jpg\"></a></td><td valign=\"top\">Crummy is &copy; 1996-2020 Leonard Richardson. Unless otherwise noted, all text licensed under a <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">Creative Commons License</a>.</td></tr></table></span><!--<rdf:RDF xmlns=\"http://web.resource.org/cc/\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"><Work rdf:about=\"http://www.crummy.com/\"><dc:title>Crummy: The Site</dc:title><dc:rights><Agent><dc:title>Crummy: the Site</dc:title></Agent></dc:rights><dc:format>text/html</dc:format><license rdf:resource=http://creativecommons.org/licenses/by-sa/2.0//></Work><License rdf:about=\"http://creativecommons.org/licenses/by-sa/2.0/\"></License></rdf:RDF>--></p></td><td valign=top><p><b>Document tree:</b>\n",
      "<dl><dd><a href=\"http://www.crummy.com/\">http://www.crummy.com/</a><dl><dd><a href=\"http://www.crummy.com/software/\">software/</a><dl><dd><a href=\"http://www.crummy.com/software/BeautifulSoup/\">BeautifulSoup/</a></dl>\n",
      "</dl>\n",
      "</dl>\n",
      "\n",
      "\n",
      "Site Search:\n",
      "\n",
      "<form method=\"get\" action=\"/search/\">\n",
      "        <input type=\"text\" name=\"q\" maxlength=\"255\" value=\"\"></input>\n",
      "        </form>\n",
      "        </td>\n",
      "\n",
      "</tr>\n",
      "\n",
      "</table>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = 'http://www.crummy.com/software/BeautifulSoup'\n",
    "source = requests.get(url).text\n",
    "print(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5**:\n",
    "\n",
    "* Is the word 'Alice' mentioned on the beautiful soup homepage?\n",
    "* How often does the word 'Soup' occur on the site?\n",
    "    - hint: use `.count()`\n",
    "* At what index occurs the substring 'alien video games' ?\n",
    "    - hint: use `.find()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 5:**\n",
    "The word 'Alice' is not found in the beautiful soup hompage.\n",
    "\n",
    "The word 'Soup' occurs 49 times on the site. \n",
    "    \n",
    "The substring 'alien video games' does not have an index because it is not found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not find 'Alice' in the text\n",
      "49\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import urllib\n",
    "\n",
    "## your code here\n",
    "## is 'Alice' in source?\n",
    "if re.search('Alice', source):\n",
    "    print('There is \\'Alice\\' in the text')\n",
    "else:\n",
    "    print('Did not find \\'Alice\\' in the text')\n",
    "\n",
    "## count occurences of 'Soup'\n",
    "print(source.count('Soup'))\n",
    "\n",
    "## find index of 'alien video games'\n",
    "print(source.find('alien video games'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beautiful Soup**\n",
    "\n",
    "* designed to make your life easier\n",
    "* many good functions for parsing html code\n",
    "\n",
    "Some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing the 2 print statements\n",
      "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\" \"http://www.w3.org/TR/REC-html40/transitional.dtd\">\n",
      "<html>\n",
      "<head>\n",
      "<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n",
      "<title>Beautiful Soup: We called him Tortoise because he taught us.</title>\n",
      "<link href=\"mailto:leonardr@segfault.org\" rev=\"made\"/>\n",
      "<link href=\"/nb/themes/Default/nb.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "<meta content=\"Beautiful Soup: a library designed for screen-scraping HTML and XML.\" name=\"Description\"/>\n",
      "<meta content=\"Markov Approximation 1.4 (module: leonardr)\" name=\"generator\"/>\n",
      "<meta content=\"Leonard Richardson\" name=\"author\"/>\n",
      "</head>\n",
      "<body alink=\"red\" bgcolor=\"white\" link=\"blue\" text=\"black\" vlink=\"660066\">\n",
      "<style>\n",
      "#tidelift { }\n",
      "\n",
      "#tidelift a {\n",
      " border: 1px solid #666666;\n",
      " margin-left: auto;\n",
      " padding: 10px;\n",
      " text-decoration: none;\n",
      "}\n",
      "\n",
      "#tidelift .cta {\n",
      " background: url(\"tidelift.svg\") no-repeat;\n",
      " padding-left: 30px;\n",
      "}\n",
      "</style>\n",
      "<img align=\"right\" src=\"10.1.jpg\" width=\"250\"/><br/>\n",
      "<p>[ <a href=\"#Download\">Download</a> | <a href=\"bs4/doc/\">Documentation</a> | <a href=\"#HallOfFame\">Hall of Fame</a> | <a href=\"enterprise.html\">For enterprise</a> | <a href=\"https://code.launchpad.net/beautifulsoup\">Source</a> | <a href=\"https://bazaar.launchpad.net/%7Eleonardr/beautifulsoup/bs4/view/head:/CHANGELOG\">Changelog</a> | <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">Discussion group</a>  | <a href=\"zine/\">Zine</a> ]</p>\n",
      "<div align=\"center\">\n",
      "<a href=\"bs4/download/\"><h1>Beautiful Soup</h1></a>\n",
      "</div>\n",
      "<p>You didn't write that awful page. You're just trying to get some\n",
      "data out of it. Beautiful Soup is here to help. Since 2004, it's been\n",
      "saving programmers hours or days of work on quick-turnaround\n",
      "screen scraping projects.</p>\n",
      "<p>Beautiful Soup is a Python library designed for quick turnaround\n",
      "projects like screen-scraping. Three features make it powerful:\n",
      "\n",
      "</p><ol>\n",
      "<li>Beautiful Soup provides a few simple methods and Pythonic idioms\n",
      "for navigating, searching, and modifying a parse tree: a toolkit for\n",
      "dissecting a document and extracting what you need. It doesn't take\n",
      "much code to write an application\n",
      "\n",
      "</li><li>Beautiful Soup automatically converts incoming documents to\n",
      "Unicode and outgoing documents to UTF-8. You don't have to think\n",
      "about encodings, unless the document doesn't specify an encoding and\n",
      "Beautiful Soup can't detect one. Then you just have to specify the\n",
      "original encoding.\n",
      "\n",
      "</li><li>Beautiful Soup sits on top of popular Python parsers like <a href=\"http://lxml.de/\">lxml</a> and <a href=\"http://code.google.com/p/html5lib/\">html5lib</a>, allowing you\n",
      "to try out different parsing strategies or trade speed for\n",
      "flexibility.\n",
      "\n",
      "</li></ol>\n",
      "<p>Beautiful Soup parses anything you give it, and does the tree\n",
      "traversal stuff for you. You can tell it \"Find all the links\", or\n",
      "\"Find all the links of class <tt>externalLink</tt>\", or \"Find all the\n",
      "links whose urls match \"foo.com\", or \"Find the table heading that's\n",
      "got bold text, then give me that text.\"\n",
      "\n",
      "</p><p>Valuable data that was once locked up in poorly-designed websites\n",
      "is now within your reach. Projects that would have taken hours take\n",
      "only minutes with Beautiful Soup.\n",
      "\n",
      "</p><p>Interested? <a href=\"bs4/doc/\">Read more.</a>\n",
      "</p><h3>Getting and giving support</h3>\n",
      "<div align=\"center\" id=\"tidelift\">\n",
      "<a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&amp;utm_medium=referral&amp;utm_campaign=enterprise\" target=\"_blank\">\n",
      "<span class=\"cta\">\n",
      "  Beautiful Soup for enterprise available via Tidelift\n",
      " </span>\n",
      "</a>\n",
      "</div>\n",
      "<p>If you have questions, send them to <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">the discussion\n",
      "group</a>. If you find a bug, <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file it on Launchpad</a>. If it's a security vulnerability, report it confidentially through <a href=\"https://tidelift.com/security\">Tidelift</a>.</p>\n",
      "<p>If you use Beautiful Soup as part of your work, please consider a <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&amp;utm_medium=referral&amp;utm_campaign=website\">Tidelift subscription</a>. This will support many of the free software projects your organization depends on, not just Beautiful Soup.\n",
      "\n",
      "\n",
      "</p><p>If Beautiful Soup is useful to you on a personal level, you might like to read <a href=\"zine/\"><i>Tool Safety</i></a>, a short zine I wrote about what I learned about software development from working on Beautiful Soup. Thanks!</p>\n",
      "<a name=\"Download\"><h2>Download Beautiful Soup</h2></a>\n",
      "<p>The current release is <a href=\"bs4/download/\">Beautiful Soup\n",
      "4.8.2</a> (December 24, 2019). You can install Beautiful Soup 4 with\n",
      "<code>pip install beautifulsoup4</code>.\n",
      "\n",
      "</p><p>In Debian and Ubuntu, Beautiful Soup is available as the\n",
      "<code>python-bs4</code> package (for Python 2) or the\n",
      "<code>python3-bs4</code> package (for Python 3). In Fedora it's\n",
      "available as the <code>python-beautifulsoup4</code> package.\n",
      "\n",
      "</p><p>Beautiful Soup is licensed under the MIT license, so you can also\n",
      "download the tarball, drop the <code>bs4/</code> directory into almost\n",
      "any Python application (or into your library path) and start using it\n",
      "immediately. (If you want to do this under Python 3, you will need to\n",
      "manually convert the code using <code>2to3</code>.)\n",
      "\n",
      "</p><p>Beautiful Soup 4 works on both Python 2 (2.7+) and Python\n",
      "3. Support for Python 2 will be discontinued on or after December 31,\n",
      "2020—one year after the Python 2 sunsetting date.\n",
      "\n",
      "</p><h3>Beautiful Soup 3</h3>\n",
      "<p>Beautiful Soup 3 was the official release line of Beautiful Soup\n",
      "from May 2006 to March 2012. It does not support Python 3 and it will\n",
      "be discontinued on or after December 31, 2020—one year after the\n",
      "Python 2 sunsetting date. If you have any active projects using\n",
      "Beautiful Soup 3, you should migrate to Beautiful Soup 4 as part of\n",
      "your Python 3 conversion.\n",
      "\n",
      "</p><p><a href=\"http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html\">Here's\n",
      "the Beautiful Soup 3 documentation.</a>\n",
      "</p><p>The current and hopefully final release of Beautiful Soup 3 is <a href=\"download/3.x/BeautifulSoup-3.2.2.tar.gz\">3.2.2</a> (October 5,\n",
      "2019). It's the <code>BeautifulSoup</code> package on pip. It's also\n",
      "available as <code>python-beautifulsoup</code> in Debian and Ubuntu,\n",
      "and as <code>python-BeautifulSoup</code> in Fedora.\n",
      "\n",
      "</p><p>Once Beautiful Soup 3 is discontinued, these package names will be available for use by a more recent version of Beautiful Soup.\n",
      "\n",
      "</p><p>Beautiful Soup 3, like Beautiful Soup 4, is <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup?utm_source=pypi-beautifulsoup&amp;utm_medium=referral&amp;utm_campaign=website\">supported through Tidelift</a>.</p>\n",
      "<a name=\"HallOfFame\"><h2>Hall of Fame</h2></a>\n",
      "<p>Over the years, Beautiful Soup has been used in hundreds of\n",
      "different projects. There's no way I can list them all, but I want to\n",
      "highlight a few high-profile projects. Beautiful Soup isn't what makes\n",
      "these projects interesting, but it did make their completion easier:\n",
      "\n",
      "</p><ul>\n",
      "<li><a href=\"http://www.nytimes.com/2007/10/25/arts/design/25vide.html\">\"Movable\n",
      " Type\"</a>, a work of digital art on display in the lobby of the New\n",
      " York Times building, uses Beautiful Soup to scrape news feeds.\n",
      "\n",
      "</li><li>Reddit uses Beautiful Soup to <a href=\"https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py\">parse\n",
      "a page that's been linked to and find a representative image</a>.\n",
      "\n",
      "</li><li>Alexander Harrowell uses Beautiful Soup to <a href=\"http://www.harrowell.org.uk/viktormap.html\">track the business\n",
      " activities</a> of an arms merchant.\n",
      "\n",
      "</li><li>The developers of Python itself used Beautiful Soup to <a href=\"http://svn.python.org/view/tracker/importer/\">migrate the Python\n",
      "bug tracker from Sourceforge to Roundup</a>.\n",
      "\n",
      "</li><li>The <a href=\"http://www2.ljworld.com/\">Lawrence Journal-World</a>\n",
      "uses Beautiful Soup to <a href=\"http://www.b-list.org/weblog/2010/nov/02/news-done-broke/\">gather\n",
      "statewide election results</a>.\n",
      "\n",
      "</li><li>The <a href=\"http://esrl.noaa.gov/gsd/fab/\">NOAA's Forecast\n",
      "Applications Branch</a> uses Beautiful Soup in <a href=\"http://laps.noaa.gov/topograbber/\">TopoGrabber</a>, a script for\n",
      "downloading \"high resolution USGS datasets.\"\n",
      "\n",
      "</li></ul>\n",
      "<p>If you've used Beautiful Soup in a project you'd like me to know\n",
      "about, please do send email to me or <a href=\"http://groups.google.com/group/beautifulsoup/\">the discussion\n",
      "group</a>.\n",
      "\n",
      "</p><h2>Development</h2>\n",
      "<p>Development happens at <a href=\"https://launchpad.net/beautifulsoup\">Launchpad</a>. You can <a href=\"https://code.launchpad.net/beautifulsoup/\">get the source\n",
      "code</a> or <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file\n",
      "bugs</a>.</p><hr/><table><tr><td valign=\"top\">\n",
      "<p>This document (<a href=\"/source/software/BeautifulSoup/index.bhtml\">source</a>) is part of Crummy, the webspace of <a href=\"/self/\">Leonard Richardson</a> (<a href=\"/self/contact.html\">contact information</a>). It was last modified on Friday, January 31 2020, 13:44:05 Nowhere Standard Time and last built on Monday, February 17 2020, 04:00:02 Nowhere Standard Time.</p><p></p><table class=\"licenseText\"><tr><td><a href=\"http://creativecommons.org/licenses/by-sa/2.0/\"><img border=\"0\" src=\"/nb//resources/img/somerights20.jpg\"/></a></td><td valign=\"top\">Crummy is © 1996-2020 Leonard Richardson. Unless otherwise noted, all text licensed under a <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">Creative Commons License</a>.</td></tr></table><!--<rdf:RDF xmlns=\"http://web.resource.org/cc/\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"><Work rdf:about=\"http://www.crummy.com/\"><dc:title>Crummy: The Site</dc:title><dc:rights><Agent><dc:title>Crummy: the Site</dc:title></Agent></dc:rights><dc:format>text/html</dc:format><license rdf:resource=http://creativecommons.org/licenses/by-sa/2.0//></Work><License rdf:about=\"http://creativecommons.org/licenses/by-sa/2.0/\"></License></rdf:RDF>--></td><td valign=\"top\"><p><b>Document tree:</b>\n",
      "</p><dl><dd><a href=\"http://www.crummy.com/\">http://www.crummy.com/</a><dl><dd><a href=\"http://www.crummy.com/software/\">software/</a><dl><dd><a href=\"http://www.crummy.com/software/BeautifulSoup/\">BeautifulSoup/</a></dd></dl>\n",
      "</dd></dl>\n",
      "</dd></dl>\n",
      "\n",
      "\n",
      "Site Search:\n",
      "\n",
      "<form action=\"/search/\" method=\"get\">\n",
      "<input maxlength=\"255\" name=\"q\" type=\"text\" value=\"\"/>\n",
      "</form>\n",
      "</td>\n",
      "</tr>\n",
      "</table>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\" \"http://www.w3.org/TR/REC-html40/transitional.dtd\">\n",
      "<html>\n",
      " <head>\n",
      "  <meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n",
      "  <title>\n",
      "   Beautiful Soup: We called him Tortoise because he taught us.\n",
      "  </title>\n",
      "  <link href=\"mailto:leonardr@segfault.org\" rev=\"made\"/>\n",
      "  <link href=\"/nb/themes/Default/nb.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "  <meta content=\"Beautiful Soup: a library designed for screen-scraping HTML and XML.\" name=\"Description\"/>\n",
      "  <meta content=\"Markov Approximation 1.4 (module: leonardr)\" name=\"generator\"/>\n",
      "  <meta content=\"Leonard Richardson\" name=\"author\"/>\n",
      " </head>\n",
      " <body alink=\"red\" bgcolor=\"white\" link=\"blue\" text=\"black\" vlink=\"660066\">\n",
      "  <style>\n",
      "   #tidelift { }\n",
      "\n",
      "#tidelift a {\n",
      " border: 1px solid #666666;\n",
      " margin-left: auto;\n",
      " padding: 10px;\n",
      " text-decoration: none;\n",
      "}\n",
      "\n",
      "#tidelift .cta {\n",
      " background: url(\"tidelift.svg\") no-repeat;\n",
      " padding-left: 30px;\n",
      "}\n",
      "  </style>\n",
      "  <img align=\"right\" src=\"10.1.jpg\" width=\"250\"/>\n",
      "  <br/>\n",
      "  <p>\n",
      "   [\n",
      "   <a href=\"#Download\">\n",
      "    Download\n",
      "   </a>\n",
      "   |\n",
      "   <a href=\"bs4/doc/\">\n",
      "    Documentation\n",
      "   </a>\n",
      "   |\n",
      "   <a href=\"#HallOfFame\">\n",
      "    Hall of Fame\n",
      "   </a>\n",
      "   |\n",
      "   <a href=\"enterprise.html\">\n",
      "    For enterprise\n",
      "   </a>\n",
      "   |\n",
      "   <a href=\"https://code.launchpad.net/beautifulsoup\">\n",
      "    Source\n",
      "   </a>\n",
      "   |\n",
      "   <a href=\"https://bazaar.launchpad.net/%7Eleonardr/beautifulsoup/bs4/view/head:/CHANGELOG\">\n",
      "    Changelog\n",
      "   </a>\n",
      "   |\n",
      "   <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">\n",
      "    Discussion group\n",
      "   </a>\n",
      "   |\n",
      "   <a href=\"zine/\">\n",
      "    Zine\n",
      "   </a>\n",
      "   ]\n",
      "  </p>\n",
      "  <div align=\"center\">\n",
      "   <a href=\"bs4/download/\">\n",
      "    <h1>\n",
      "     Beautiful Soup\n",
      "    </h1>\n",
      "   </a>\n",
      "  </div>\n",
      "  <p>\n",
      "   You didn't write that awful page. You're just trying to get some\n",
      "data out of it. Beautiful Soup is here to help. Since 2004, it's been\n",
      "saving programmers hours or days of work on quick-turnaround\n",
      "screen scraping projects.\n",
      "  </p>\n",
      "  <p>\n",
      "   Beautiful Soup is a Python library designed for quick turnaround\n",
      "projects like screen-scraping. Three features make it powerful:\n",
      "  </p>\n",
      "  <ol>\n",
      "   <li>\n",
      "    Beautiful Soup provides a few simple methods and Pythonic idioms\n",
      "for navigating, searching, and modifying a parse tree: a toolkit for\n",
      "dissecting a document and extracting what you need. It doesn't take\n",
      "much code to write an application\n",
      "   </li>\n",
      "   <li>\n",
      "    Beautiful Soup automatically converts incoming documents to\n",
      "Unicode and outgoing documents to UTF-8. You don't have to think\n",
      "about encodings, unless the document doesn't specify an encoding and\n",
      "Beautiful Soup can't detect one. Then you just have to specify the\n",
      "original encoding.\n",
      "   </li>\n",
      "   <li>\n",
      "    Beautiful Soup sits on top of popular Python parsers like\n",
      "    <a href=\"http://lxml.de/\">\n",
      "     lxml\n",
      "    </a>\n",
      "    and\n",
      "    <a href=\"http://code.google.com/p/html5lib/\">\n",
      "     html5lib\n",
      "    </a>\n",
      "    , allowing you\n",
      "to try out different parsing strategies or trade speed for\n",
      "flexibility.\n",
      "   </li>\n",
      "  </ol>\n",
      "  <p>\n",
      "   Beautiful Soup parses anything you give it, and does the tree\n",
      "traversal stuff for you. You can tell it \"Find all the links\", or\n",
      "\"Find all the links of class\n",
      "   <tt>\n",
      "    externalLink\n",
      "   </tt>\n",
      "   \", or \"Find all the\n",
      "links whose urls match \"foo.com\", or \"Find the table heading that's\n",
      "got bold text, then give me that text.\"\n",
      "  </p>\n",
      "  <p>\n",
      "   Valuable data that was once locked up in poorly-designed websites\n",
      "is now within your reach. Projects that would have taken hours take\n",
      "only minutes with Beautiful Soup.\n",
      "  </p>\n",
      "  <p>\n",
      "   Interested?\n",
      "   <a href=\"bs4/doc/\">\n",
      "    Read more.\n",
      "   </a>\n",
      "  </p>\n",
      "  <h3>\n",
      "   Getting and giving support\n",
      "  </h3>\n",
      "  <div align=\"center\" id=\"tidelift\">\n",
      "   <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&amp;utm_medium=referral&amp;utm_campaign=enterprise\" target=\"_blank\">\n",
      "    <span class=\"cta\">\n",
      "     Beautiful Soup for enterprise available via Tidelift\n",
      "    </span>\n",
      "   </a>\n",
      "  </div>\n",
      "  <p>\n",
      "   If you have questions, send them to\n",
      "   <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">\n",
      "    the discussion\n",
      "group\n",
      "   </a>\n",
      "   . If you find a bug,\n",
      "   <a href=\"https://bugs.launchpad.net/beautifulsoup/\">\n",
      "    file it on Launchpad\n",
      "   </a>\n",
      "   . If it's a security vulnerability, report it confidentially through\n",
      "   <a href=\"https://tidelift.com/security\">\n",
      "    Tidelift\n",
      "   </a>\n",
      "   .\n",
      "  </p>\n",
      "  <p>\n",
      "   If you use Beautiful Soup as part of your work, please consider a\n",
      "   <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&amp;utm_medium=referral&amp;utm_campaign=website\">\n",
      "    Tidelift subscription\n",
      "   </a>\n",
      "   . This will support many of the free software projects your organization depends on, not just Beautiful Soup.\n",
      "  </p>\n",
      "  <p>\n",
      "   If Beautiful Soup is useful to you on a personal level, you might like to read\n",
      "   <a href=\"zine/\">\n",
      "    <i>\n",
      "     Tool Safety\n",
      "    </i>\n",
      "   </a>\n",
      "   , a short zine I wrote about what I learned about software development from working on Beautiful Soup. Thanks!\n",
      "  </p>\n",
      "  <a name=\"Download\">\n",
      "   <h2>\n",
      "    Download Beautiful Soup\n",
      "   </h2>\n",
      "  </a>\n",
      "  <p>\n",
      "   The current release is\n",
      "   <a href=\"bs4/download/\">\n",
      "    Beautiful Soup\n",
      "4.8.2\n",
      "   </a>\n",
      "   (December 24, 2019). You can install Beautiful Soup 4 with\n",
      "   <code>\n",
      "    pip install beautifulsoup4\n",
      "   </code>\n",
      "   .\n",
      "  </p>\n",
      "  <p>\n",
      "   In Debian and Ubuntu, Beautiful Soup is available as the\n",
      "   <code>\n",
      "    python-bs4\n",
      "   </code>\n",
      "   package (for Python 2) or the\n",
      "   <code>\n",
      "    python3-bs4\n",
      "   </code>\n",
      "   package (for Python 3). In Fedora it's\n",
      "available as the\n",
      "   <code>\n",
      "    python-beautifulsoup4\n",
      "   </code>\n",
      "   package.\n",
      "  </p>\n",
      "  <p>\n",
      "   Beautiful Soup is licensed under the MIT license, so you can also\n",
      "download the tarball, drop the\n",
      "   <code>\n",
      "    bs4/\n",
      "   </code>\n",
      "   directory into almost\n",
      "any Python application (or into your library path) and start using it\n",
      "immediately. (If you want to do this under Python 3, you will need to\n",
      "manually convert the code using\n",
      "   <code>\n",
      "    2to3\n",
      "   </code>\n",
      "   .)\n",
      "  </p>\n",
      "  <p>\n",
      "   Beautiful Soup 4 works on both Python 2 (2.7+) and Python\n",
      "3. Support for Python 2 will be discontinued on or after December 31,\n",
      "2020—one year after the Python 2 sunsetting date.\n",
      "  </p>\n",
      "  <h3>\n",
      "   Beautiful Soup 3\n",
      "  </h3>\n",
      "  <p>\n",
      "   Beautiful Soup 3 was the official release line of Beautiful Soup\n",
      "from May 2006 to March 2012. It does not support Python 3 and it will\n",
      "be discontinued on or after December 31, 2020—one year after the\n",
      "Python 2 sunsetting date. If you have any active projects using\n",
      "Beautiful Soup 3, you should migrate to Beautiful Soup 4 as part of\n",
      "your Python 3 conversion.\n",
      "  </p>\n",
      "  <p>\n",
      "   <a href=\"http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html\">\n",
      "    Here's\n",
      "the Beautiful Soup 3 documentation.\n",
      "   </a>\n",
      "  </p>\n",
      "  <p>\n",
      "   The current and hopefully final release of Beautiful Soup 3 is\n",
      "   <a href=\"download/3.x/BeautifulSoup-3.2.2.tar.gz\">\n",
      "    3.2.2\n",
      "   </a>\n",
      "   (October 5,\n",
      "2019). It's the\n",
      "   <code>\n",
      "    BeautifulSoup\n",
      "   </code>\n",
      "   package on pip. It's also\n",
      "available as\n",
      "   <code>\n",
      "    python-beautifulsoup\n",
      "   </code>\n",
      "   in Debian and Ubuntu,\n",
      "and as\n",
      "   <code>\n",
      "    python-BeautifulSoup\n",
      "   </code>\n",
      "   in Fedora.\n",
      "  </p>\n",
      "  <p>\n",
      "   Once Beautiful Soup 3 is discontinued, these package names will be available for use by a more recent version of Beautiful Soup.\n",
      "  </p>\n",
      "  <p>\n",
      "   Beautiful Soup 3, like Beautiful Soup 4, is\n",
      "   <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup?utm_source=pypi-beautifulsoup&amp;utm_medium=referral&amp;utm_campaign=website\">\n",
      "    supported through Tidelift\n",
      "   </a>\n",
      "   .\n",
      "  </p>\n",
      "  <a name=\"HallOfFame\">\n",
      "   <h2>\n",
      "    Hall of Fame\n",
      "   </h2>\n",
      "  </a>\n",
      "  <p>\n",
      "   Over the years, Beautiful Soup has been used in hundreds of\n",
      "different projects. There's no way I can list them all, but I want to\n",
      "highlight a few high-profile projects. Beautiful Soup isn't what makes\n",
      "these projects interesting, but it did make their completion easier:\n",
      "  </p>\n",
      "  <ul>\n",
      "   <li>\n",
      "    <a href=\"http://www.nytimes.com/2007/10/25/arts/design/25vide.html\">\n",
      "     \"Movable\n",
      " Type\"\n",
      "    </a>\n",
      "    , a work of digital art on display in the lobby of the New\n",
      " York Times building, uses Beautiful Soup to scrape news feeds.\n",
      "   </li>\n",
      "   <li>\n",
      "    Reddit uses Beautiful Soup to\n",
      "    <a href=\"https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py\">\n",
      "     parse\n",
      "a page that's been linked to and find a representative image\n",
      "    </a>\n",
      "    .\n",
      "   </li>\n",
      "   <li>\n",
      "    Alexander Harrowell uses Beautiful Soup to\n",
      "    <a href=\"http://www.harrowell.org.uk/viktormap.html\">\n",
      "     track the business\n",
      " activities\n",
      "    </a>\n",
      "    of an arms merchant.\n",
      "   </li>\n",
      "   <li>\n",
      "    The developers of Python itself used Beautiful Soup to\n",
      "    <a href=\"http://svn.python.org/view/tracker/importer/\">\n",
      "     migrate the Python\n",
      "bug tracker from Sourceforge to Roundup\n",
      "    </a>\n",
      "    .\n",
      "   </li>\n",
      "   <li>\n",
      "    The\n",
      "    <a href=\"http://www2.ljworld.com/\">\n",
      "     Lawrence Journal-World\n",
      "    </a>\n",
      "    uses Beautiful Soup to\n",
      "    <a href=\"http://www.b-list.org/weblog/2010/nov/02/news-done-broke/\">\n",
      "     gather\n",
      "statewide election results\n",
      "    </a>\n",
      "    .\n",
      "   </li>\n",
      "   <li>\n",
      "    The\n",
      "    <a href=\"http://esrl.noaa.gov/gsd/fab/\">\n",
      "     NOAA's Forecast\n",
      "Applications Branch\n",
      "    </a>\n",
      "    uses Beautiful Soup in\n",
      "    <a href=\"http://laps.noaa.gov/topograbber/\">\n",
      "     TopoGrabber\n",
      "    </a>\n",
      "    , a script for\n",
      "downloading \"high resolution USGS datasets.\"\n",
      "   </li>\n",
      "  </ul>\n",
      "  <p>\n",
      "   If you've used Beautiful Soup in a project you'd like me to know\n",
      "about, please do send email to me or\n",
      "   <a href=\"http://groups.google.com/group/beautifulsoup/\">\n",
      "    the discussion\n",
      "group\n",
      "   </a>\n",
      "   .\n",
      "  </p>\n",
      "  <h2>\n",
      "   Development\n",
      "  </h2>\n",
      "  <p>\n",
      "   Development happens at\n",
      "   <a href=\"https://launchpad.net/beautifulsoup\">\n",
      "    Launchpad\n",
      "   </a>\n",
      "   . You can\n",
      "   <a href=\"https://code.launchpad.net/beautifulsoup/\">\n",
      "    get the source\n",
      "code\n",
      "   </a>\n",
      "   or\n",
      "   <a href=\"https://bugs.launchpad.net/beautifulsoup/\">\n",
      "    file\n",
      "bugs\n",
      "   </a>\n",
      "   .\n",
      "  </p>\n",
      "  <hr/>\n",
      "  <table>\n",
      "   <tr>\n",
      "    <td valign=\"top\">\n",
      "     <p>\n",
      "      This document (\n",
      "      <a href=\"/source/software/BeautifulSoup/index.bhtml\">\n",
      "       source\n",
      "      </a>\n",
      "      ) is part of Crummy, the webspace of\n",
      "      <a href=\"/self/\">\n",
      "       Leonard Richardson\n",
      "      </a>\n",
      "      (\n",
      "      <a href=\"/self/contact.html\">\n",
      "       contact information\n",
      "      </a>\n",
      "      ). It was last modified on Friday, January 31 2020, 13:44:05 Nowhere Standard Time and last built on Monday, February 17 2020, 04:00:02 Nowhere Standard Time.\n",
      "     </p>\n",
      "     <p>\n",
      "     </p>\n",
      "     <table class=\"licenseText\">\n",
      "      <tr>\n",
      "       <td>\n",
      "        <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">\n",
      "         <img border=\"0\" src=\"/nb//resources/img/somerights20.jpg\"/>\n",
      "        </a>\n",
      "       </td>\n",
      "       <td valign=\"top\">\n",
      "        Crummy is © 1996-2020 Leonard Richardson. Unless otherwise noted, all text licensed under a\n",
      "        <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">\n",
      "         Creative Commons License\n",
      "        </a>\n",
      "        .\n",
      "       </td>\n",
      "      </tr>\n",
      "     </table>\n",
      "     <!--<rdf:RDF xmlns=\"http://web.resource.org/cc/\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"><Work rdf:about=\"http://www.crummy.com/\"><dc:title>Crummy: The Site</dc:title><dc:rights><Agent><dc:title>Crummy: the Site</dc:title></Agent></dc:rights><dc:format>text/html</dc:format><license rdf:resource=http://creativecommons.org/licenses/by-sa/2.0//></Work><License rdf:about=\"http://creativecommons.org/licenses/by-sa/2.0/\"></License></rdf:RDF>-->\n",
      "    </td>\n",
      "    <td valign=\"top\">\n",
      "     <p>\n",
      "      <b>\n",
      "       Document tree:\n",
      "      </b>\n",
      "     </p>\n",
      "     <dl>\n",
      "      <dd>\n",
      "       <a href=\"http://www.crummy.com/\">\n",
      "        http://www.crummy.com/\n",
      "       </a>\n",
      "       <dl>\n",
      "        <dd>\n",
      "         <a href=\"http://www.crummy.com/software/\">\n",
      "          software/\n",
      "         </a>\n",
      "         <dl>\n",
      "          <dd>\n",
      "           <a href=\"http://www.crummy.com/software/BeautifulSoup/\">\n",
      "            BeautifulSoup/\n",
      "           </a>\n",
      "          </dd>\n",
      "         </dl>\n",
      "        </dd>\n",
      "       </dl>\n",
      "      </dd>\n",
      "     </dl>\n",
      "     Site Search:\n",
      "     <form action=\"/search/\" method=\"get\">\n",
      "      <input maxlength=\"255\" name=\"q\" type=\"text\" value=\"\"/>\n",
      "     </form>\n",
      "    </td>\n",
      "   </tr>\n",
      "  </table>\n",
      " </body>\n",
      "</html>\n",
      "\n",
      "[<a href=\"#Download\">Download</a>, <a href=\"bs4/doc/\">Documentation</a>, <a href=\"#HallOfFame\">Hall of Fame</a>, <a href=\"enterprise.html\">For enterprise</a>, <a href=\"https://code.launchpad.net/beautifulsoup\">Source</a>, <a href=\"https://bazaar.launchpad.net/%7Eleonardr/beautifulsoup/bs4/view/head:/CHANGELOG\">Changelog</a>, <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">Discussion group</a>, <a href=\"zine/\">Zine</a>, <a href=\"bs4/download/\"><h1>Beautiful Soup</h1></a>, <a href=\"http://lxml.de/\">lxml</a>, <a href=\"http://code.google.com/p/html5lib/\">html5lib</a>, <a href=\"bs4/doc/\">Read more.</a>, <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&amp;utm_medium=referral&amp;utm_campaign=enterprise\" target=\"_blank\">\n",
      "<span class=\"cta\">\n",
      "  Beautiful Soup for enterprise available via Tidelift\n",
      " </span>\n",
      "</a>, <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">the discussion\n",
      "group</a>, <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file it on Launchpad</a>, <a href=\"https://tidelift.com/security\">Tidelift</a>, <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&amp;utm_medium=referral&amp;utm_campaign=website\">Tidelift subscription</a>, <a href=\"zine/\"><i>Tool Safety</i></a>, <a name=\"Download\"><h2>Download Beautiful Soup</h2></a>, <a href=\"bs4/download/\">Beautiful Soup\n",
      "4.8.2</a>, <a href=\"http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html\">Here's\n",
      "the Beautiful Soup 3 documentation.</a>, <a href=\"download/3.x/BeautifulSoup-3.2.2.tar.gz\">3.2.2</a>, <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup?utm_source=pypi-beautifulsoup&amp;utm_medium=referral&amp;utm_campaign=website\">supported through Tidelift</a>, <a name=\"HallOfFame\"><h2>Hall of Fame</h2></a>, <a href=\"http://www.nytimes.com/2007/10/25/arts/design/25vide.html\">\"Movable\n",
      " Type\"</a>, <a href=\"https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py\">parse\n",
      "a page that's been linked to and find a representative image</a>, <a href=\"http://www.harrowell.org.uk/viktormap.html\">track the business\n",
      " activities</a>, <a href=\"http://svn.python.org/view/tracker/importer/\">migrate the Python\n",
      "bug tracker from Sourceforge to Roundup</a>, <a href=\"http://www2.ljworld.com/\">Lawrence Journal-World</a>, <a href=\"http://www.b-list.org/weblog/2010/nov/02/news-done-broke/\">gather\n",
      "statewide election results</a>, <a href=\"http://esrl.noaa.gov/gsd/fab/\">NOAA's Forecast\n",
      "Applications Branch</a>, <a href=\"http://laps.noaa.gov/topograbber/\">TopoGrabber</a>, <a href=\"http://groups.google.com/group/beautifulsoup/\">the discussion\n",
      "group</a>, <a href=\"https://launchpad.net/beautifulsoup\">Launchpad</a>, <a href=\"https://code.launchpad.net/beautifulsoup/\">get the source\n",
      "code</a>, <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file\n",
      "bugs</a>, <a href=\"/source/software/BeautifulSoup/index.bhtml\">source</a>, <a href=\"/self/\">Leonard Richardson</a>, <a href=\"/self/contact.html\">contact information</a>, <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\"><img border=\"0\" src=\"/nb//resources/img/somerights20.jpg\"/></a>, <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">Creative Commons License</a>, <a href=\"http://www.crummy.com/\">http://www.crummy.com/</a>, <a href=\"http://www.crummy.com/software/\">software/</a>, <a href=\"http://www.crummy.com/software/BeautifulSoup/\">BeautifulSoup/</a>]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "## get bs4 object\n",
    "soup = bs4.BeautifulSoup(source)\n",
    " \n",
    "## compare the two print statements\n",
    "print(\"Comparing the 2 print statements\")\n",
    "print(soup)\n",
    "print(soup.prettify())\n",
    "\n",
    "# prettify() method gives the HTML structure with all the indentation\n",
    "# just exactly how one might expect when viewing the HTML source of a webpage\n",
    "# unlike just printing out the HTML string, which does not have any indentation\n",
    "\n",
    "## show how to find all a tags\n",
    "print(soup.findAll('a'))\n",
    "\n",
    "## ***Why does this not work? ***\n",
    "# because .findAll specifically looks for HTML tags, not for any particular substring\n",
    "print(soup.findAll('Soup'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"#Download\">Download</a>\n",
      "#Download\n",
      "['#Download', 'bs4/doc/', '#HallOfFame', 'enterprise.html', 'https://code.launchpad.net/beautifulsoup', 'https://bazaar.launchpad.net/%7Eleonardr/beautifulsoup/bs4/view/head:/CHANGELOG', 'https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup', 'zine/', 'bs4/download/', 'http://lxml.de/', 'http://code.google.com/p/html5lib/', 'bs4/doc/', 'https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&utm_medium=referral&utm_campaign=enterprise', 'https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup', 'https://bugs.launchpad.net/beautifulsoup/', 'https://tidelift.com/security', 'https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&utm_medium=referral&utm_campaign=website', 'zine/', None, 'bs4/download/', 'http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html', 'download/3.x/BeautifulSoup-3.2.2.tar.gz', 'https://tidelift.com/subscription/pkg/pypi-beautifulsoup?utm_source=pypi-beautifulsoup&utm_medium=referral&utm_campaign=website', None, 'http://www.nytimes.com/2007/10/25/arts/design/25vide.html', 'https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py', 'http://www.harrowell.org.uk/viktormap.html', 'http://svn.python.org/view/tracker/importer/', 'http://www2.ljworld.com/', 'http://www.b-list.org/weblog/2010/nov/02/news-done-broke/', 'http://esrl.noaa.gov/gsd/fab/', 'http://laps.noaa.gov/topograbber/', 'http://groups.google.com/group/beautifulsoup/', 'https://launchpad.net/beautifulsoup', 'https://code.launchpad.net/beautifulsoup/', 'https://bugs.launchpad.net/beautifulsoup/', '/source/software/BeautifulSoup/index.bhtml', '/self/', '/self/contact.html', 'http://creativecommons.org/licenses/by-sa/2.0/', 'http://creativecommons.org/licenses/by-sa/2.0/', 'http://www.crummy.com/', 'http://www.crummy.com/software/', 'http://www.crummy.com/software/BeautifulSoup/']\n"
     ]
    }
   ],
   "source": [
    "## get attribute value from an element:\n",
    "## find tag: this only returns the first occurrence, \n",
    "## not all tags in the string\n",
    "first_tag = soup.find('a')\n",
    "print(first_tag)\n",
    "\n",
    "## get attribute `href`\n",
    "print(first_tag.get('href'))\n",
    "\n",
    "## get all links in the page\n",
    "link_list = [l.get('href') for l in soup.findAll('a')]\n",
    "print(link_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-227-0aee102cbae1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# if it starts with 'http' we are happy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlink_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'http'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mexternal_links\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "## filter all external links\n",
    "# create an empty list to collect the valid links\n",
    "external_links = []\n",
    "\n",
    "# write a loop to filter the links\n",
    "# if it starts with 'http' we are happy\n",
    "for l in link_list:\n",
    "    if l[:4] == 'http':\n",
    "        external_links.append(l)\n",
    "\n",
    "# this throws an error! It says something about 'NoneType'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# lets investigate. Have a close look at the link_list:\n",
    "link_list\n",
    "\n",
    "# Seems that there are None elements! Let's verify:\n",
    "print(sum([l is None for l in link_list]))\n",
    "\n",
    "# So there are two elements in the list that are None!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://code.launchpad.net/beautifulsoup',\n",
       " 'https://bazaar.launchpad.net/%7Eleonardr/beautifulsoup/bs4/view/head:/CHANGELOG',\n",
       " 'https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup',\n",
       " 'http://lxml.de/',\n",
       " 'http://code.google.com/p/html5lib/',\n",
       " 'https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&utm_medium=referral&utm_campaign=enterprise',\n",
       " 'https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup',\n",
       " 'https://bugs.launchpad.net/beautifulsoup/',\n",
       " 'https://tidelift.com/security',\n",
       " 'https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&utm_medium=referral&utm_campaign=website',\n",
       " 'http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html',\n",
       " 'https://tidelift.com/subscription/pkg/pypi-beautifulsoup?utm_source=pypi-beautifulsoup&utm_medium=referral&utm_campaign=website',\n",
       " 'http://www.nytimes.com/2007/10/25/arts/design/25vide.html',\n",
       " 'https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py',\n",
       " 'http://www.harrowell.org.uk/viktormap.html',\n",
       " 'http://svn.python.org/view/tracker/importer/',\n",
       " 'http://www2.ljworld.com/',\n",
       " 'http://www.b-list.org/weblog/2010/nov/02/news-done-broke/',\n",
       " 'http://esrl.noaa.gov/gsd/fab/',\n",
       " 'http://laps.noaa.gov/topograbber/',\n",
       " 'http://groups.google.com/group/beautifulsoup/',\n",
       " 'https://launchpad.net/beautifulsoup',\n",
       " 'https://code.launchpad.net/beautifulsoup/',\n",
       " 'https://bugs.launchpad.net/beautifulsoup/',\n",
       " 'http://creativecommons.org/licenses/by-sa/2.0/',\n",
       " 'http://creativecommons.org/licenses/by-sa/2.0/',\n",
       " 'http://www.crummy.com/',\n",
       " 'http://www.crummy.com/software/',\n",
       " 'http://www.crummy.com/software/BeautifulSoup/']"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's filter those objects out in the for loop\n",
    "external_links = []\n",
    "\n",
    "# write a loop to filter the links\n",
    "# if it is not None and starts with 'http' we are happy\n",
    "for l in link_list:\n",
    "    if l is not None and l[:4] == 'http':\n",
    "        external_links.append(l)\n",
    "        \n",
    "external_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: The above `if` condition works because of lazy evaluation in Python. The `and` statement becomes `False` if the first part is `False`, so there is no need to ever evaluate the second part. Thus a `None` entry in the list gets never asked about its first four characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://code.launchpad.net/beautifulsoup',\n",
       " 'https://bazaar.launchpad.net/%7Eleonardr/beautifulsoup/bs4/view/head:/CHANGELOG',\n",
       " 'https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup',\n",
       " 'http://lxml.de/',\n",
       " 'http://code.google.com/p/html5lib/',\n",
       " 'https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&utm_medium=referral&utm_campaign=enterprise',\n",
       " 'https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup',\n",
       " 'https://bugs.launchpad.net/beautifulsoup/',\n",
       " 'https://tidelift.com/security',\n",
       " 'https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&utm_medium=referral&utm_campaign=website',\n",
       " 'http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html',\n",
       " 'https://tidelift.com/subscription/pkg/pypi-beautifulsoup?utm_source=pypi-beautifulsoup&utm_medium=referral&utm_campaign=website',\n",
       " 'http://www.nytimes.com/2007/10/25/arts/design/25vide.html',\n",
       " 'https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py',\n",
       " 'http://www.harrowell.org.uk/viktormap.html',\n",
       " 'http://svn.python.org/view/tracker/importer/',\n",
       " 'http://www2.ljworld.com/',\n",
       " 'http://www.b-list.org/weblog/2010/nov/02/news-done-broke/',\n",
       " 'http://esrl.noaa.gov/gsd/fab/',\n",
       " 'http://laps.noaa.gov/topograbber/',\n",
       " 'http://groups.google.com/group/beautifulsoup/',\n",
       " 'https://launchpad.net/beautifulsoup',\n",
       " 'https://code.launchpad.net/beautifulsoup/',\n",
       " 'https://bugs.launchpad.net/beautifulsoup/',\n",
       " 'http://creativecommons.org/licenses/by-sa/2.0/',\n",
       " 'http://creativecommons.org/licenses/by-sa/2.0/',\n",
       " 'http://www.crummy.com/',\n",
       " 'http://www.crummy.com/software/',\n",
       " 'http://www.crummy.com/software/BeautifulSoup/']"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can put this in a list comprehension as well, \n",
    "# it almost reads like a sentence.\n",
    "\n",
    "[l for l in link_list if l is not None and l.startswith('http')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing the Tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a title Test Hello world!\n"
     ]
    }
   ],
   "source": [
    "# redefining `s` without any line breaks\n",
    "s = \"\"\"<!DOCTYPE html><html><head><title>This is a title</title></head><body><h3> Test </h3><p>Hello world!</p></body></html>\"\"\"\n",
    "## get bs4 object\n",
    "tree = bs4.BeautifulSoup(s)\n",
    "\n",
    "## get html root node\n",
    "root_node = tree.html\n",
    "\n",
    "## get head from root using contents\n",
    "head = root_node.contents[0]\n",
    "\n",
    "## get body from root\n",
    "body = root_node.contents[1]\n",
    "\n",
    "## could directly access body\n",
    "tree.body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6**:\n",
    "\n",
    "* Find the `h3` tag by parsing the tree starting at `body`\n",
    "* Create a list of all __Hall of Fame__ entries listed on the Beautiful Soup webpage\n",
    "    - hint: it is the only unordered list in the page (tag `ul`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<li>Reddit uses Beautiful Soup to <a href=\"https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py\">parse\\na page that\\'s been linked to and find a representative image</a>.\\n\\n</li>', '<li>Alexander Harrowell uses Beautiful Soup to <a href=\"http://www.harrowell.org.uk/viktormap.html\">track the business\\n activities</a> of an arms merchant.\\n\\n</li>', '<li>The developers of Python itself used Beautiful Soup to <a href=\"http://svn.python.org/view/tracker/importer/\">migrate the Python\\nbug tracker from Sourceforge to Roundup</a>.\\n\\n</li>', '<li>The <a href=\"http://www2.ljworld.com/\">Lawrence Journal-World</a>\\nuses Beautiful Soup to <a href=\"http://www.b-list.org/weblog/2010/nov/02/news-done-broke/\">gather\\nstatewide election results</a>.\\n\\n</li>', '<li>The <a href=\"http://esrl.noaa.gov/gsd/fab/\">NOAA\\'s Forecast\\nApplications Branch</a> uses Beautiful Soup in <a href=\"http://laps.noaa.gov/topograbber/\">TopoGrabber</a>, a script for\\ndownloading \"high resolution USGS datasets.\"\\n\\n</li>']\n"
     ]
    }
   ],
   "source": [
    "## your code here\n",
    "## get h3 tag from body\n",
    "root_soup = soup.html\n",
    "head_soup = soup.contents[0]\n",
    "body_soup = soup.contents[1]\n",
    "tags = body_soup.findAll('h3')\n",
    "\n",
    "## use ul as entry point\n",
    "ul_entry_pt = soup.find('ul')\n",
    "all_li = ul_entry_pt.findAll('li')\n",
    "\n",
    "## get hall of fame list from entry point\n",
    "## skip the first entry \n",
    "hall_of_fame = []\n",
    "for i in range(1, len(all_li)):\n",
    "    hall_of_fame.append(str(all_li[i]))\n",
    "    \n",
    "print(hall_of_fame)\n",
    "\n",
    "## reformat into a list containing strings\n",
    "## it is ok to have a list of lists\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tmp` now is actually a list of lists containing the hall of fame entries. \n",
    "Here is some advanced Python on how to print really just one entry per list item.\n",
    "\n",
    "The cool things about this are: \n",
    "* The use of `\"\"` to just access the `join` function of strings.\n",
    "* The `join` function itself\n",
    "* that you can actually have two nested for loops in a list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<li>Reddit uses Beautiful Soup to <a href=\"https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py\">parse\n",
      "a page that's been linked to and find a representative image</a>.\n",
      "\n",
      "</li>\n",
      "<li>Alexander Harrowell uses Beautiful Soup to <a href=\"http://www.harrowell.org.uk/viktormap.html\">track the business\n",
      " activities</a> of an arms merchant.\n",
      "\n",
      "</li>\n",
      "<li>The developers of Python itself used Beautiful Soup to <a href=\"http://svn.python.org/view/tracker/importer/\">migrate the Python\n",
      "bug tracker from Sourceforge to Roundup</a>.\n",
      "\n",
      "</li>\n",
      "<li>The <a href=\"http://www2.ljworld.com/\">Lawrence Journal-World</a>\n",
      "uses Beautiful Soup to <a href=\"http://www.b-list.org/weblog/2010/nov/02/news-done-broke/\">gather\n",
      "statewide election results</a>.\n",
      "\n",
      "</li>\n",
      "<li>The <a href=\"http://esrl.noaa.gov/gsd/fab/\">NOAA's Forecast\n",
      "Applications Branch</a> uses Beautiful Soup in <a href=\"http://laps.noaa.gov/topograbber/\">TopoGrabber</a>, a script for\n",
      "downloading \"high resolution USGS datasets.\"\n",
      "\n",
      "</li>\n"
     ]
    }
   ],
   "source": [
    "tmp = hall_of_fame\n",
    "test =  [\"\".join(str(a) for a in sublist) for sublist in tmp]\n",
    "print('\\n'.join(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7**:\n",
    "- Explain in detail what is Python doing in the previous line\n",
    "\n",
    "**Question 8**:\n",
    "- Plot a histogram of the count of the 20 most common words in the html file\n",
    "- Plot a histogram of the count of the 20 most common words in the visible part (what is displayed in the browser) of the html file\n",
    "\n",
    "**Deliverable**: For Lab 3.B and 3.C submit a modified version fo this .ipynb file that contains all the answers to the quesitons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 7:** For the second line, this is a list comprehension. The list comprehension command looks through each sublist and in each sublist is a string, essentially, these strings are joined together so in the end, we would have an array of joined substrings.\n",
    "\n",
    "Then the third line just joins all the lines together with the endline character so when we print it out, each string gets its own line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 8**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "INVISIBLE_ELEMS = ('style', 'script', 'head', 'title')\n",
    "RE_SPACES = re.compile(r'\\s{3,}')\n",
    "\n",
    "def visible_texts(soup):\n",
    "    \"\"\" get visible text from a document \"\"\"\n",
    "    text = ' '.join([\n",
    "        s for s in soup.strings\n",
    "        if s.parent.name not in INVISIBLE_ELEMS\n",
    "    ])\n",
    "    # collapse multiple spaces to two spaces.\n",
    "    return RE_SPACES.sub('  ', text)\n",
    "\n",
    "def all_html(soup):\n",
    "    \"\"\" get all text from a document \"\"\"\n",
    "    text = ' '.join([\n",
    "        s for s in soup.strings\n",
    "    ])\n",
    "    # collapse multiple spaces to two spaces.\n",
    "    return RE_SPACES.sub('  ', text)\n",
    "\n",
    "\n",
    "def plot_common_words(myStr, num_words):\n",
    "    \n",
    "    # to replace all the punctuations\n",
    "    for word in myStr.lower().split():\n",
    "        word = word.replace(\".\",\"\")\n",
    "        word = word.replace(\",\",\"\")\n",
    "        word = word.replace(\":\",\"\")\n",
    "        word = word.replace(\"\\\"\",\"\")\n",
    "        word = word.replace(\"!\",\"\")\n",
    "        word = word.replace(\"â€œ\",\"\")\n",
    "        word = word.replace(\"â€˜\",\"\")\n",
    "        word = word.replace(\"*\",\"\")\n",
    "        word = word.replace('|',\"\")\n",
    "        word = word.replace(\"{\",\"\")\n",
    "        word = word.replace(\"}\",\"\")\n",
    "    \n",
    "    # implementing Counter\n",
    "    myDict = Counter(myStr.split())\n",
    "\n",
    "    # sorting myDict based on each key's value in ascending order\n",
    "    myDict = {k: v for k, v in sorted(myDict.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "    # because Counter also counts individual character like 'e' as well!!!\n",
    "    # We need to filter those out!\n",
    "    myDict = {k: v for k, v in myDict.items() if v > 1 and len(k) > 1}\n",
    "    \n",
    "    top_n_dict = {}\n",
    "    count = num_words\n",
    "    for k, v in myDict.items():\n",
    "        \n",
    "        if count == 0:\n",
    "            break\n",
    "        \n",
    "        # only get top num_words entries\n",
    "        top_n_dict[k] = v\n",
    "        count -= 1\n",
    "        \n",
    "    # to convert dictionary in which each key is a value to a col\n",
    "    # and its corresponding value is another value to another col\n",
    "    # to pandas frame\n",
    "    # must use .items()\n",
    "    df = pd.DataFrame(top_n_dict.items(), columns = ['Word', 'Count'])\n",
    "    df.plot.bar(x='Word',y='Count')\n",
    "    \n",
    "#Plot a histogram of the count of the 20 most common words in the html file\n",
    "# the same effect occurs for myStr = soup.text as well\n",
    "myStr = all_html(soup)\n",
    "plot_common_words(myStr, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Beautiful Soup: We called him Tortoise because he taught us.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#tidelift { }\n",
      "\n",
      "#tidelift a {\n",
      " border: 1px solid #666666;\n",
      " margin-left: auto;\n",
      " padding: 10px;\n",
      " text-decoration: none;\n",
      "}\n",
      "\n",
      "#tidelift .cta {\n",
      " background: url(\"tidelift.svg\") no-repeat;\n",
      " padding-left: 30px;\n",
      "}\n",
      "\n",
      "\n",
      "[ Download | Documentation | Hall of Fame | For enterprise | Source | Changelog | Discussion group  | Zine ]\n",
      "\n",
      "Beautiful Soup\n",
      "\n",
      "You didn't write that awful page. You're just trying to get some\n",
      "data out of it. Beautiful Soup is here to help. Since 2004, it's been\n",
      "saving programmers hours or days of work on quick-turnaround\n",
      "screen scraping projects.\n",
      "Beautiful Soup is a Python library designed for quick turnaround\n",
      "projects like screen-scraping. Three features make it powerful:\n",
      "\n",
      "\n",
      "Beautiful Soup provides a few simple methods and Pythonic idioms\n",
      "for navigating, searching, and modifying a parse tree: a toolkit for\n",
      "dissecting a document and extracting what you need. It doesn't take\n",
      "much code to write an application\n",
      "\n",
      "Beautiful Soup automatically converts incoming documents to\n",
      "Unicode and outgoing documents to UTF-8. You don't have to think\n",
      "about encodings, unless the document doesn't specify an encoding and\n",
      "Beautiful Soup can't detect one. Then you just have to specify the\n",
      "original encoding.\n",
      "\n",
      "Beautiful Soup sits on top of popular Python parsers like lxml and html5lib, allowing you\n",
      "to try out different parsing strategies or trade speed for\n",
      "flexibility.\n",
      "\n",
      "\n",
      "Beautiful Soup parses anything you give it, and does the tree\n",
      "traversal stuff for you. You can tell it \"Find all the links\", or\n",
      "\"Find all the links of class externalLink\", or \"Find all the\n",
      "links whose urls match \"foo.com\", or \"Find the table heading that's\n",
      "got bold text, then give me that text.\"\n",
      "\n",
      "Valuable data that was once locked up in poorly-designed websites\n",
      "is now within your reach. Projects that would have taken hours take\n",
      "only minutes with Beautiful Soup.\n",
      "\n",
      "Interested? Read more.\n",
      "Getting and giving support\n",
      "\n",
      "\n",
      "\n",
      "  Beautiful Soup for enterprise available via Tidelift\n",
      " \n",
      "\n",
      "\n",
      "If you have questions, send them to the discussion\n",
      "group. If you find a bug, file it on Launchpad. If it's a security vulnerability, report it confidentially through Tidelift.\n",
      "If you use Beautiful Soup as part of your work, please consider a Tidelift subscription. This will support many of the free software projects your organization depends on, not just Beautiful Soup.\n",
      "\n",
      "\n",
      "If Beautiful Soup is useful to you on a personal level, you might like to read Tool Safety, a short zine I wrote about what I learned about software development from working on Beautiful Soup. Thanks!\n",
      "Download Beautiful Soup\n",
      "The current release is Beautiful Soup\n",
      "4.8.2 (December 24, 2019). You can install Beautiful Soup 4 with\n",
      "pip install beautifulsoup4.\n",
      "\n",
      "In Debian and Ubuntu, Beautiful Soup is available as the\n",
      "python-bs4 package (for Python 2) or the\n",
      "python3-bs4 package (for Python 3). In Fedora it's\n",
      "available as the python-beautifulsoup4 package.\n",
      "\n",
      "Beautiful Soup is licensed under the MIT license, so you can also\n",
      "download the tarball, drop the bs4/ directory into almost\n",
      "any Python application (or into your library path) and start using it\n",
      "immediately. (If you want to do this under Python 3, you will need to\n",
      "manually convert the code using 2to3.)\n",
      "\n",
      "Beautiful Soup 4 works on both Python 2 (2.7+) and Python\n",
      "3. Support for Python 2 will be discontinued on or after December 31,\n",
      "2020—one year after the Python 2 sunsetting date.\n",
      "\n",
      "Beautiful Soup 3\n",
      "Beautiful Soup 3 was the official release line of Beautiful Soup\n",
      "from May 2006 to March 2012. It does not support Python 3 and it will\n",
      "be discontinued on or after December 31, 2020—one year after the\n",
      "Python 2 sunsetting date. If you have any active projects using\n",
      "Beautiful Soup 3, you should migrate to Beautiful Soup 4 as part of\n",
      "your Python 3 conversion.\n",
      "\n",
      "Here's\n",
      "the Beautiful Soup 3 documentation.\n",
      "The current and hopefully final release of Beautiful Soup 3 is 3.2.2 (October 5,\n",
      "2019). It's the BeautifulSoup package on pip. It's also\n",
      "available as python-beautifulsoup in Debian and Ubuntu,\n",
      "and as python-BeautifulSoup in Fedora.\n",
      "\n",
      "Once Beautiful Soup 3 is discontinued, these package names will be available for use by a more recent version of Beautiful Soup.\n",
      "\n",
      "Beautiful Soup 3, like Beautiful Soup 4, is supported through Tidelift.\n",
      "Hall of Fame\n",
      "Over the years, Beautiful Soup has been used in hundreds of\n",
      "different projects. There's no way I can list them all, but I want to\n",
      "highlight a few high-profile projects. Beautiful Soup isn't what makes\n",
      "these projects interesting, but it did make their completion easier:\n",
      "\n",
      "\n",
      "\"Movable\n",
      " Type\", a work of digital art on display in the lobby of the New\n",
      " York Times building, uses Beautiful Soup to scrape news feeds.\n",
      "\n",
      "Reddit uses Beautiful Soup to parse\n",
      "a page that's been linked to and find a representative image.\n",
      "\n",
      "Alexander Harrowell uses Beautiful Soup to track the business\n",
      " activities of an arms merchant.\n",
      "\n",
      "The developers of Python itself used Beautiful Soup to migrate the Python\n",
      "bug tracker from Sourceforge to Roundup.\n",
      "\n",
      "The Lawrence Journal-World\n",
      "uses Beautiful Soup to gather\n",
      "statewide election results.\n",
      "\n",
      "The NOAA's Forecast\n",
      "Applications Branch uses Beautiful Soup in TopoGrabber, a script for\n",
      "downloading \"high resolution USGS datasets.\"\n",
      "\n",
      "\n",
      "If you've used Beautiful Soup in a project you'd like me to know\n",
      "about, please do send email to me or the discussion\n",
      "group.\n",
      "\n",
      "Development\n",
      "Development happens at Launchpad. You can get the source\n",
      "code or file\n",
      "bugs.\n",
      "This document (source) is part of Crummy, the webspace of Leonard Richardson (contact information). It was last modified on Friday, January 31 2020, 13:44:05 Nowhere Standard Time and last built on Monday, February 17 2020, 04:00:02 Nowhere Standard Time.Crummy is © 1996-2020 Leonard Richardson. Unless otherwise noted, all text licensed under a Creative Commons License.Document tree:\n",
      "http://www.crummy.com/software/BeautifulSoup/\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Site Search:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(body_soup.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find the 20 most common words in the visible part of the HTML file\n",
    "myStr = visible_texts(soup)\n",
    "plot_common_words(myStr, 20)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
